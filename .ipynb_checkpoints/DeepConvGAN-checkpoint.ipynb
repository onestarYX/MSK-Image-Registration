{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import layers as custom_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "# We renamed cusolver64_11.dll to cusolver64_10.dll to solve the compatibility issue.\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File Paths\n",
    "imgIdxCsvPath = './MRNet/MRNet-v1.0/similar.csv'\n",
    "MRI_Path = './MRNet/MRNet-v1.0/train/axial/{}.npy'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load self-generated training data (by data loaders)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Duplicate fixed image as labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDataPath = \"./affineTrainingData/affine{}.npz\"\n",
    "trainDataSize = 2000\n",
    "fixedImg = np.load(MRI_Path.format(\"0701\"))\n",
    "fixedImg = fixedImg / np.max(fixedImg)\n",
    "fixedImg = fixedImg.astype('float32')\n",
    "fixedImg = np.expand_dims(fixedImg, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Returns a batch of training image pairs.\n",
    "\"\"\"\n",
    "def image_input_gen(batch_size = 5):\n",
    "    while True:\n",
    "        imgPair_batch = np.zeros((batch_size, *fixedImg.shape[:-1], 2))\n",
    "        for i in range(batch_size):\n",
    "            idx = random.randrange(trainDataSize)\n",
    "            inputObj = np.load(trainDataPath.format(idx))\n",
    "            movingImg = inputObj['img']\n",
    "            movingImg = np.expand_dims(movingImg, axis=-1)\n",
    "            movingImg = movingImg.astype('float32')\n",
    "            imgPair = np.concatenate([movingImg, fixedImg], axis=3)\n",
    "            imgPair_batch[i] = imgPair\n",
    "        \n",
    "        yield imgPair_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def data_generator(batch_size = 5):\n",
    "#     while True:\n",
    "#         imgPair_batch = np.zeros((batch_size, *fixedImg.shape[:-1], 2))\n",
    "#         fixedImg_batch = np.zeros((batch_size, *fixedImg.shape))\n",
    "#         tgtAffineTrf_batch = np.zeros((batch_size, 12))\n",
    "#         for i in range(batch_size):\n",
    "#             idx = random.randrange(trainDataSize)\n",
    "#             inputObj = np.load(trainDataPath.format(idx))\n",
    "#             movingImg = inputObj['img']\n",
    "#             movingImg = np.expand_dims(movingImg, axis=-1)\n",
    "#             movingImg = movingImg.astype('float32')\n",
    "#             imgPair = np.concatenate([movingImg, fixedImg], axis=3)\n",
    "#             imgPair_batch[i] = imgPair\n",
    "\n",
    "#             tgtAffineTrf = inputObj['trf']\n",
    "#             tgtAffineTrf = tgtAffineTrf.astype('float32')\n",
    "#             tgtAffineTrf_batch[i] = tgtAffineTrf\n",
    "#             fixedImg_batch[i] = fixedImg\n",
    "        \n",
    "#         yield (imgPair_batch, [fixedImg_batch, tgtAffineTrf_batch])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the Generator and the Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_activation(x, alpha=0.3):\n",
    "    x = layers.LeakyReLU(alpha=alpha)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Generator\n",
    "\"\"\"\n",
    "inputs = keras.Input(shape = (*fixedImg.shape[:-1], 2))\n",
    "moving_input = tf.expand_dims(inputs[:, :, :, :, 0], axis = -1)\n",
    "# fixed_input = tf.expand_dims(inputs[:, :, :, :, 1], axis = -1)\n",
    "\n",
    "down_depths = [32, 64, 128, 256, 512]\n",
    "up_depths = [2, 16, 32, 16, 3]\n",
    "kernel_size = (7, 7, 7)\n",
    "\n",
    "x = layers.Conv3D(filters=down_depths[0], kernel_size=(6, 32, 32), strides=(2, 2, 2), activation=\"relu\")(inputs)\n",
    "# x = layers.MaxPool3D((1, 2, 2))(x)\n",
    "print(\"0: {}\".format(x.shape))\n",
    "\n",
    "x = layers.Conv3D(filters=down_depths[0], kernel_size=(6, 32, 32), strides=(1, 2, 2))(x)\n",
    "x = conv_activation(x)\n",
    "f_conv_1 = layers.Conv3D(filters=down_depths[1], kernel_size=(6, 16, 16), strides=(2, 2, 2), )(f_conv_0)\n",
    "f_conv_1 = layers.BatchNormalization()(f_conv_1)\n",
    "f_conv_2 = layers.Conv3D(filters=down_depths[2], kernel_size=(6, 8, 8), activation=\"relu\")(f_conv_1)\n",
    "f_conv_2 = layers.BatchNormalization()(f_conv_2)\n",
    "f_conv_3 = layers.Conv3D(filters=down_depths[3], kernel_size=(4, 8, 8), strides=(1, 2, 2), activation=\"relu\")(f_conv_2)\n",
    "f_conv_3 = layers.BatchNormalization()(f_conv_3)\n",
    "f_conv_4 = layers.Conv3D(filters=down_depths[4], kernel_size=(4, 4, 4), activation=\"relu\")(f_conv_3)\n",
    "f_conv_4 = layers.BatchNormalization()(f_conv_4)\n",
    "\n",
    "# concat_feats = tf.concat([conv_4, f_conv_4], axis = -1)\n",
    "# print(concat_feats.shape)\n",
    "\n",
    "x = layers.AveragePooling3D((2, 2, 2))(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(512)(x)\n",
    "x = layers.BatchNormalization(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "# x = layers.Dropout(0.2)(x)\n",
    "x = layers.Dense(64)(x)\n",
    "x = layers.BatchNormalization(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "affine_pred = layers.Dense(12, activation=\"linear\", name=\"affine_pred\")(x)\n",
    "\n",
    "# convTransposed_3 = layers.Conv3DTranspose(filters=up_depths[0], kernel_size=(6, 10, 10), activation=\"relu\")(conv_4)\n",
    "# print(\"convTransposed_3: {}\".format(convTransposed_3.shape))\n",
    "# filtered_convTransposed_2 = layers.Conv3DTranspose(filters=up_depths[1], kernel_size=(6, 20, 20), activation=\"relu\")(convTransposed_3)\n",
    "# print(\"filtered_convTransposed_2: {}\".format(filtered_convTransposed_2.shape))\n",
    "# convTransposed_2 = layers.UpSampling3D((1, 2, 2))(filtered_convTransposed_2)\n",
    "# print(\"convTransposed_2: {}\".format(convTransposed_2.shape))\n",
    "# filtered_convTransposed_1 = layers.Conv3DTranspose(filters=up_depths[2], kernel_size=(3, 15, 15), activation=\"relu\")(convTransposed_2)\n",
    "# print(\"filtered_convTransposed_1: {}\".format(filtered_convTransposed_1.shape))\n",
    "# convTransposed_1 = layers.UpSampling3D((2, 2, 2))(filtered_convTransposed_1)\n",
    "# print(\"convTransposed_1: {}\".format(convTransposed_1.shape))\n",
    "# convTransposed_0 = layers.Conv3DTranspose(filters=up_depths[3], kernel_size=(3, 16, 16), activation=\"relu\")(convTransposed_1)\n",
    "# print(\"convTransposed_0: {}\".format(convTransposed_0.shape))\n",
    "# deformation_field_pred = layers.Conv3DTranspose(filters=up_depths[4], kernel_size=(3, 10, 10), activation=\"relu\")(convTransposed_0)\n",
    "# print(\"deformation_field_pred: {}\".format(deformation_field_pred.shape))\n",
    "\n",
    "affine_warped = custom_layers.SpatialTransformer(interp_method='linear', add_identity=False, name=\"warped_image\", shift_center=True)([moving_input, affine_pred])\n",
    "# deformable_warped = custom_layers.SpatialTransformer(interp_method='linear', add_identity=False, name=\"warped_image\", shift_center=False)([affine_warped, deformation_field_pred])\n",
    "print(affine_warped.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = keras.Model(inputs=inputs, outputs=[affine_warped, affine_pred], name=\"combined_model\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataGen = data_generator(batch_size = 1)\n",
    "moving_test, label_test = next(dataGen)\n",
    "print(moving_test.shape)\n",
    "(warped_test, affine_pred_test) = model(moving_test)\n",
    "print(label_test[1])\n",
    "print(label_test[1].dtype)\n",
    "print(affine_pred_test)\n",
    "mse = tf.keras.losses.MeanSquaredError()\n",
    "print(mse(label_test[1], affine_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "keras.utils.plot_model(model, \"test.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate = lr)\n",
    "# loss_object = tf.keras.losses.MeanSquaredError()\n",
    "\n",
    "loss_history = []\n",
    "save_callback = ModelCheckpoint('./checkpoints/{epoch:02d}.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "y = (deformed_img, affine_trf)\n",
    "\"\"\"\n",
    "def affine_loss(y_actual, y_pred):\n",
    "    y_actual = y_actual[0]\n",
    "    y_pred = y_pred[0]\n",
    "    tgtDiag = [y_actual[0]] + [y_actual[5]] + [y_actual[10]]\n",
    "    predDiag = [y_pred[0]] + [y_pred[5]] + [y_pred[10]]\n",
    "    tgtCorner = y_actual[1:3] + [y_actual[4]] + [y_actual[6]] + y_actual[8:10]\n",
    "    predCorner = y_pred[1:3] + [y_pred[4]] + [y_pred[6]] + y_pred[8:10]\n",
    "    tgtTranslation = [y_actual[3]] + [y_actual[7]] + [y_actual[11]]\n",
    "    predTranslation = [y_pred[3]] + [y_pred[7]] + [y_pred[11]]\n",
    "    mse = tf.keras.losses.MeanSquaredError()\n",
    "    diag_loss = mse(tgtDiag, predDiag)\n",
    "    corner_loss = mse(tgtCorner, predCorner)\n",
    "    translation_loss = mse(tgtTranslation, predTranslation)\n",
    "    return corner_loss * 10 + diag_loss * 10 + translation_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimizer,\n",
    "              loss={\"warped_image\":\"mean_squared_error\", \"affine_pred\":\"mean_squared_error\"},\n",
    "#               loss_weights={\"warped_image\":1, \"affine_pred\":1},\n",
    "              run_eagerly=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataGen = data_generator(batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.fit(dataGen, epochs=20, steps_per_epoch=trainDataSize/4, callbacks=[save_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test model (output == warpedImg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testModel = keras.Model(inputs=inputs, outputs=[affine_warped, affine_pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testModel.load_weights('./checkpoints/epoch_{}'.format(epochs-1))\n",
    "testModel.load_weights('./checkpoints/13.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataGen_test = data_generator(batch_size = 1)\n",
    "moving_test, label_test = next(dataGen_test)\n",
    "(warped_test, affine_pred_test) = testModel(moving_test)\n",
    "print(label_test[1])\n",
    "print(affine_pred_test)\n",
    "mse = tf.keras.losses.MeanSquaredError()\n",
    "print(mse(label_test[1], affine_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sliceToCheck = 0\n",
    "fig, axs = plt.subplots(5, 3, figsize=(15, 35))\n",
    "for i in range(5):\n",
    "    axs[i, 0].imshow(fixedImg[sliceToCheck + i * 5,:,:,0])\n",
    "    axs[i, 0].set_title(\"Fixed Image\")\n",
    "    axs[i, 1].imshow(moving_test[0,sliceToCheck + i * 5,:,:,0])\n",
    "    axs[i, 1].set_title(\"Moving Image\")\n",
    "    axs[i, 2].imshow(warped_test[0,sliceToCheck + i * 5,:,:,0])\n",
    "    axs[i, 2].set_title(\"Warped Image\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
